{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generation of Level 1 data with romanisim and processing it with romancal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imports\n",
    " Libraries used\n",
    "- *subprocess* for running scripts from command line \n",
    "- *numpy* to handle array functions\n",
    "- *pandas* for working with tabular data\n",
    "- *matplotlib.pyplot* for plotting data\n",
    "- *astropy.io* wrting csv files\n",
    "- *astropy.time* creating a time object \n",
    "- *astroquery.gaia* querying and downloading the Gaia data\n",
    "- *romanisim.gaia* querying and downloading the Gaia data\n",
    "- *romancal.pipeline* for running the processing pipeline\n",
    "- *asdf* for reading and writing asdf files\n",
    "- *roman_datamodels* for reading and writing asdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from  matplotlib.colors import LogNorm\n",
    "import astropy.io \n",
    "from astroquery.gaia import Gaia\n",
    "import asdf\n",
    "import roman_datamodels as rdm\n",
    "from romancal.pipeline import ExposurePipeline\n",
    "import romanisim.gaia\n",
    "import astropy.time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "The purpose of this notebook is to show how to generate simulated Level 1 and Level 2 roman data with ```romanisim``` and then process Level 1 data with ```romancal``` to produce Level 2 data. Additionally, we show  how to open, explore and work with the generated data files.  \n",
    "\n",
    "\n",
    "Details about the roman data levels can be found [here](https://roman-docs.stsci.edu/data-handbook-home/wfi-data-format/data-levels-and-products). Broadly speaking Level 1 is three-dimensional data cube (one dimension for time and two dimensions for image coorrdinates) that represents a single uncalibrated ramp exposure (unit DN).  More specifically, it is shaped as an array with shape (N resultants, 4096 image rows, 4096 image columns). The Level 2 WFI data are calibrated rate images in instrumental units of (photo)electrons / second (eâ€“ / sec). \n",
    "\n",
    "The ```romancal``` pipeline also detects sources in the Level 2 images. A list of activities we perform here is as follows. We generate catalogs to be used as input by ```romanisim```, both synthetically and by querying the Gaia archive. Then we run romanisim and ```romancal```.\n",
    "Next we move on to analysis. We read the source list and view Level 2 image cutouts around the identified sources. We plot ramps from Level 1 corresponding to these identified sources. Finally, we estimate slopes of these ramps and compare the values with those in the Level 2 images.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading data\n",
    "In this tutorial ```romanisim``` is used to generate simulated data. \n",
    "It takes as input a catalog that specifies the list of targets to be simulated. Currently it simulates two types of targets, point sources labelled by type ```PSF``` (e.g stars) and extended sources labelled by ```SER``` (e.g. galaxies).\n",
    "We begin by defining a utility function to generate a catalog that can be passed on to ```romanisim```.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Make input catalog for romanisim synthetically.    \n",
    "Make a catalog in csv format to be used as input with ```romanisim```, specifying the targets to be simulated.\n",
    "Targets are distributed uniformly over a rectangular patch (aspect ratio 2:1, minor axis pointing north) \n",
    "with user specified center coordinates and area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def make_catalog_synthetic(outfile_name, ra, dec, bandpass='F158', n_ser=0, n_psf=0, area=0.24, seed=12):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    outfile_name (str): output file name\n",
    "    ra (float): ra of the center of WFI  [deg]\n",
    "    dec (float): dec of the center of WFI  [deg]\n",
    "    bandpass (str): Photometric bandpasss e.g F158\n",
    "    flux (float): flux in [maggies], such that AB magnitude = -2.5*log(flux) \n",
    "    n_sources (int): number of sources to simulate\n",
    "    area (float): Area over which sources are distributed [square degrees]     \n",
    "    seed (int): Seed for random number generator\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    scale=np.sqrt(area/18.0)\n",
    "    # total number of sources\n",
    "    n_sources=n_psf+n_ser\n",
    "    d={}\n",
    "    d['ra']=ra+(np.random.uniform(size=n_sources)-0.5)*scale*6/np.cos(np.radians(dec))\n",
    "    d['dec']=dec+(np.random.uniform(size=n_sources)-0.5)*scale*3    \n",
    "    # set the type 'PSF' and 'SER' \n",
    "    d['type']=np.array(['PSF']*n_psf+['SER']*n_ser)\n",
    "    # set sersic index of sources in range [2, 4]\n",
    "    d['n']=np.int64(2+np.random.uniform(size=n_sources)*2)\n",
    "    # set half light radius radius [3, 8]\n",
    "    d['half_light_radius']=3+np.random.uniform(size=n_sources)*5\n",
    "    # set position angle in range [0,90]\n",
    "    d['pa']=np.random.uniform(size=n_sources)*90.0\n",
    "    # set major to minor axis ratio in range [0.3,0.7]\n",
    "    d['ba']=0.3+np.random.uniform(size=n_sources)*0.7\n",
    "    # set bandpass flux  \n",
    "    temp1=np.power(10.0,np.random.uniform(size=n_psf))*1e-8\n",
    "    temp2=np.power(10.0,np.random.uniform(size=n_ser))*1e-7\n",
    "    d['F158']=np.concatenate([temp1,temp2])\n",
    "    # write the catalog file\n",
    "    #pandas.DataFrame(d).to_csv(filename,sep=' ',index=False)\n",
    "    astropy.io.ascii.write(d,outfile_name,overwrite=True,names=['ra','dec','type','n','half_light_radius','pa','ba','F158'])    \n",
    "    \n",
    "\n",
    "dirname='test_data/'\n",
    "if not os.path.exists(dirname):\n",
    "    os.makedirs(dirname)\n",
    "\n",
    "ra_cen, dec_cen = (0.0, 0.0)\n",
    "make_catalog_synthetic(dirname+'catalog_mixed.csv', ra_cen, dec_cen, n_ser=900,n_psf=360)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make input catalog for romanisim from Gaia\n",
    "We query the Gaia archive to do a cone serach around user specified equatorial coordiantes and then wriyte it to an [```.ecsv```](https://docs.astropy.org/en/stable/io/ascii/ecsv.html) file (a csv file with extra commented out rows at the top providing details about the columns). Flux in roman bandpass is assumed to be 1/100 times (5 magnitudes) fainter than flux in gaia bandpass  ```phot_g_mean_mag```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_catalog_gaia(outfile_name, ra, dec, date='2026-01-01', bandpasses=['F158'], radius=1.0, row_limit=1000):\n",
    "    \"\"\"\n",
    "    date (str): 'YYYY-MM-DD'  e.g. '2027-06-16' \n",
    "    radius (float): search radius in degrees\n",
    "    row_limit (int): Use -1 for unlimited\n",
    "    bandpasses list(str): list of roman bandpasses. If set to None the full list is loaded as specified in. \n",
    "    \"\"\"\n",
    "    row_limit = f'TOP {row_limit}' if row_limit > -1 else ''    \n",
    "    q = f'select {row_limit} * from gaiadr3.gaia_source where distance({ra}, {dec}, ra, dec) < {radius}'\n",
    "    job = Gaia.launch_job_async(q)\n",
    "    r = job.get_results()\n",
    "    #print(job)\n",
    "    r['phot_g_mean_mag']=r['phot_g_mean_mag']+5   \n",
    "    if bandpasses is None:\n",
    "        bandpasses=set(romanisim.bandpass.galsim2roman_bandpass.values())\n",
    "\n",
    "    if outfile_name.endswith('.ecsv'):\n",
    "        romanisim.gaia.gaia2romanisimcat(r, astropy.time.Time(date), fluxfields=set(bandpasses)).write(outfile_name, overwrite=True)\n",
    "    else:\n",
    "        raise RuntimeError('output file name should end with .ecsv')\n",
    "        \n",
    "dirname='test_data/'\n",
    "make_catalog_gaia(f\"{dirname}catalog_gaia.ecsv\",ra_cen, dec_cen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate L1 and L2 data with romanisim\n",
    "We use the command line script ```romanisim-make-image``` to generate the simulated data. One can pass a number of arguments to the script. You can checkout the usage by running the cell below or by accessing the [romanisim documentation](https://romanisim.readthedocs.io/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(subprocess.getoutput('romanisim-make-image -h'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate data for detector 2 and pass on the name of the input catalog along with other arguments as required, e.g. output filename, data level and so on. By convention Level 1 data have suffix ```_uncal```. To generate the level 2 data corresponding to a given Level 1 data, we need to make sure that the  same seed is used for the random number generator (```rng_seed```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sca=2\n",
    "exposure_no=1\n",
    "date='2026-01-01T01:00:00'\n",
    "dirname='test_data/'\n",
    "l1_fname=f\"romanisim_mixed_sca{sca}\"\n",
    "catalog_filename=dirname+'catalog_mixed.csv'\n",
    "\n",
    "level=1\n",
    "filename=f\"{dirname}{l1_fname}_uncal.asdf\"        \n",
    "cmd = f\"romanisim-make-image --radec {ra_cen} {dec_cen} --catalog {catalog_filename} --usecrds --webbpsf  --level {level} --bandpass F158 --date {date} --rng_seed 11 --sca {sca} {filename}\"\n",
    "print(cmd)\n",
    "os.system(cmd)\n",
    "\n",
    "level=2\n",
    "filename=f\"{dirname}{l1_fname}_l2.asdf\"        \n",
    "cmd = f\"romanisim-make-image --radec {ra_cen} {dec_cen} --catalog {catalog_filename} --usecrds --webbpsf  --level {level} --bandpass F158 --date {date} --rng_seed 11 --sca {sca} {filename}\"\n",
    "print(cmd)\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run romancal on L1 data.\n",
    "We now run ```romancal``` on the Level 1 data generated by ```romanisim```. To save the results the ```save_results``` argument has to be set, one can also optionally supply the output directory. The pipeline runs a series of steps one after the other. Each step can be further fine tuned by passing additional arguments via the steps keyword. The step arguments are passed on as a dictionary. In the example below we pass arguments specific to the ```source_detection``` step and the ```rampfit``` step. Note ```save_catalogs``` option has to be set in order to save the catalog. For details on steps and additional arguments see [ romancal documentation](https://roman-pipeline.readthedocs.io/en/latest/index.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_fname='romanisim_mixed_sca2'\n",
    "filename=f\"{dirname}{l1_fname}_uncal.asdf\"        \n",
    "result = ExposurePipeline.call(filename,save_results=True,output_dir=dirname,\n",
    "                               steps={'source_detection':\n",
    "                                      {'save_catalogs':True},\n",
    "                                      'rampfit':{'threshold_intercept':5.5,\n",
    "                                                 'threshold_constant':0.33}})\n",
    "\n",
    "# move catalog file to data directory\n",
    "if os.path.isfile(f\"{l1_fname}_uncal_tweakreg_catalog.asdf\"):\n",
    "    os.system(f'mv {l1_fname}_uncal_tweakreg_catalog.asdf {dirname}{l1_fname}_uncal_tweakreg_catalog.asdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and explore the L1 and L2 images generated by romanisim \n",
    "We open the Level 1 file, its cooresponding Level 2 file and the catalog of sources identfied in the Level 2 file. We use ```roman_datamodels``` to open the first two files as it provides attribute style access to the underlying data, but one can also open them ```AsdfObject``` object for dictionary style access (see notebook on How to open Roman Data Files for more details).   \n",
    "\n",
    "We examine the shape and the units of the data in the files. The L1 files are of shape 6x4096x4096 and have units of DN. The first dimension represents the time. The L2 files are of shape 4088x4088 and are in units of electrons/s. There is no time dimension as we have computed the slope or rate. The shape of image is smaller by 8 pixels as the 4 pixel border which has no science data has been removed. Finally, we print the sources contained in the catalog. The x and y coordinates of the centroid and the flux are shown. The centroid is in units of pixel and ranges between 0 to 4088."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read uncalibrated data\n",
    "l1_fname='romanisim_mixed_sca2'\n",
    "rdm1=rdm.open(f\"{dirname}{l1_fname}_uncal.asdf\")\n",
    "\n",
    "# read calibrated data\n",
    "rdm2=rdm.open(f\"{dirname}{l1_fname}_cal.asdf\")\n",
    "\n",
    "# Read the source catalog\n",
    "catalog = asdf.open(f\"{dirname}{l1_fname}_uncal_tweakreg_catalog.asdf\")['tweakreg_catalog'].copy()\n",
    "\n",
    "\n",
    "# explore shape and units of l1 and l2 data\n",
    "print(f\"l1 data   shape: {str(af1['roman']['data'].shape):16} units: {af1['roman']['data'].unit}\")\n",
    "print(f\"l2 data   shape: {str(af2['roman']['data'].shape):16} units: {af2['roman']['data'].unit}\")\n",
    "print()\n",
    "\n",
    "# print the source catalog\n",
    "print(f\"{'index':6}  {'xcentroid':8}  {'ycentroid':8} {'flux':8}\")\n",
    "print(\"-------------------------------------\")\n",
    "for i in range(catalog.size):\n",
    "    print(f\"{i:<6}  {catalog['xcentroid'][i]:<8.2f}  {catalog['ycentroid'][i]:8.2f}  {catalog['flux'][i]:<8.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print information contained in the files\n",
    "The information in the roman_datamodel object is stored in a hierarchical fashion and can be accessed using the attribute notation. The L1 object has three high level keys ```meta, data``` and ```amp33```, the L2 object has many more. To view the full list of available attributes and subattributes we use ```.info()``` member function. Try to locate the following atrribiutes, which we will use later, ```rdm1.meta.exposure.frame_time``` and ```rdm1.meta.exposure.read_pattern``` .     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('rdm1 keys')\n",
    "print('-----------')\n",
    "for key in rdm1.keys():\n",
    "    print(key)\n",
    "print('-----------')\n",
    "print('rdm2 keys')\n",
    "for key in rdm2.keys():\n",
    "    print(key)\n",
    "print('-----------')\n",
    "\n",
    "print('rdm1 info')\n",
    "print('-----------')\n",
    "rdm1.info(max_rows=None)\n",
    "print('rdm2 info')\n",
    "print('-----------')\n",
    "rdm2.info(max_rows=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Level 2 image \n",
    "We now view the Level 2 images. All panels correspond to the same image but their extent are different. Each panel is a zoomed in version of the previous one.\n",
    "One can see some points source objects (stars descibed by a PSF) and extended source objects (galaxies described by a sersic profile). The white spots are bad pixels and are to be ignored. The objects can be seen more clearly in the zoomed bottom left panel. One can read the coordinates and the flux values by sliding the cursor on the panels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image=rdm2.data.value\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "i,j=(4088//2,4088//2)\n",
    "norm = LogNorm(vmin=2,vmax=20)\n",
    "im1=axs.flat[0].imshow(image,cmap='YlOrBr_r',norm=norm,origin='lower')\n",
    "im1=axs.flat[1].imshow(image,cmap='YlOrBr_r',norm=norm,origin='lower')\n",
    "axs.flat[1].axis([i-1024,i+1024,j-1024,j+1024])\n",
    "im1=axs.flat[2].imshow(image,cmap='YlOrBr_r',norm=norm,origin='lower')\n",
    "axs.flat[2].axis([i-256,i+256,j-256,j+256])\n",
    "im1=axs.flat[3].imshow(image,cmap='YlOrBr_r',norm=norm,origin='lower')\n",
    "axs.flat[3].axis([i-64,i+64,j-64,j+64])\n",
    "fig.colorbar(im1,ax=axs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View 64x64 pixel cutouts of Level 2 images centered on detected sources\n",
    "We choose four sources from the source catalog and plot 64x64 pixel image cutouts centered on them. The first and fourth are point sources, while the second and third are extended sources. One can see that the point sources are tightly confined due to the PSF being very narrow and is undersampled.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 64x64 cutouts of l2 images centered on detected sources\n",
    "norm=LogNorm(vmin=2,vmax=100)\n",
    "fig, axs = plt.subplots(2,2)\n",
    "for j,i in enumerate([5, 6, 7 , 8]):\n",
    "    width=32\n",
    "    jp=int(catalog['xcentroid'][i])\n",
    "    ip=int(catalog['ycentroid'][i])    \n",
    "    im1=axs.flat[j].imshow(image[ip-width:ip+width,jp-width:jp+width],cmap='YlOrBr_r',norm=norm,origin='lower')\n",
    "    axs.flat[j].set_title('Source No '+str(i))       \n",
    "fig.tight_layout()\n",
    "fig.colorbar(im1,ax=axs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ramps centered on detected sources from Level 1 data and compare its slope with the value in the Level 2 data \n",
    "To plot the ramps, we being by first computing the mean time of each resultant from the read out pattern. We do crude estimate of slope by taking the difference between the first and the last resultant values and dividing it by the time difference.\n",
    "\n",
    "A few things should be kept in mind while working with Level 1 and Level 2 data. The shape of Level 1 and Level 2 are different, as there exists a 4 pixel wide border which is ignored in Level 2. Hence, a pixel (i,j) in Level 2 corresponds to pixel (i+4,j+4) in Level 1. Also the units of Level 1 are in DN while that of Level 2 data are electron/s. The ratio of electrons to DN is know as the gain which can be found in the calibration reference file. From the printed results we see that our estimated slope is in good agreement with what is shown in Level 2 data except for a factor of 2, which is due to the gain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frame_time=rdm1.meta.exposure.frame_time\n",
    "read_pattern=rdm1.meta.exposure.read_pattern\n",
    "# mean time of each resultant\n",
    "t_mean=np.array([frame_time*np.mean(t) for t in read_pattern])\n",
    "image1=rdm1.data.value\n",
    "image2=rdm2.data.value\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots()\n",
    "print(f\"{'source no':16} {'Level 2 [i,j]':16} {'ramp slope':16} {'Level 2 data':16}\")\n",
    "print(f\"{'':16} {'':16} {str(af1['roman']['data'].unit)+'/s':16} {af2['roman']['data'].unit:16}\")\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "for k in [3, 4, 5, 6]:\n",
    "    # image coordinates in Level 1\n",
    "    ip,jp=(int(catalog['ycentroid'][k])+4,int(catalog['xcentroid'][k])+4)\n",
    "    ax.plot(t_mean,image1[:,ip,jp],'-',label=f\"source no: {k}, L2_image[{ip},{jp}]\")\n",
    "    ax.plot(t_mean,image1[:,ip,jp],'k.')\n",
    "    # crude slope from Level 1\n",
    "    dt=t_mean[-1]-t_mean[0]\n",
    "    slope=(image1[-1,ip,jp]-image1[0,ip,jp])/dt\n",
    "    print(f\"{k:<16} [{ip:<4},{jp:<4}]{'':5} {slope:<16.2f} {image2[ip-4,jp-4]:<16.2f}\")\n",
    "ax.set_xlabel('Mean resultant time [s]')\n",
    "ax.set_ylabel(f\"counts [{af1['roman']['data'].unit}]\")\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aditional Resources\n",
    "- [romanisim](https://romanisim.readthedocs.io/en/latest/index.html)\n",
    "- [romancal](https://roman-pipeline.readthedocs.io/en/latest/index.html)\n",
    "- [Roman Documentation](https://roman-docs.stsci.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About this notebook\n",
    "**Author:** Sanjib Sharma, Roman Telescope Branch.  \n",
    "**Updated On:** 2024-23-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
